{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd69901",
   "metadata": {},
   "source": [
    "# FragNet baseline testing\n",
    "\n",
    "Link: [Code](https://github.com/pnnl/FragNet) [Paper](https://arxiv.org/abs/2410.12156)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565a700",
   "metadata": {},
   "source": [
    "## Setup Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42776397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'FragNet'...\n",
      "remote: Enumerating objects: 322, done.\u001b[K\n",
      "remote: Counting objects: 100% (322/322), done.\u001b[K\n",
      "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
      "remote: Total 322 (delta 152), reused 226 (delta 86), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (322/322), 34.01 MiB | 1.53 MiB/s, done.\n",
      "Resolving deltas: 100% (152/152), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pnnl/FragNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3d105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lmdb==1.4.1 (from -r requirements.txt (line 1))\n",
      "  Downloading lmdb-1.4.1.tar.gz (881 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.5/881.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ipython in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (8.37.0)\n",
      "Collecting matplotlib==3.9.2 (from -r requirements.txt (line 3))\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting networkx==2.8.8 (from -r requirements.txt (line 4))\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting numpy==1.24.1 (from -r requirements.txt (line 5))\n",
      "  Downloading numpy-1.24.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting ogb==1.2.0 (from -r requirements.txt (line 6))\n",
      "  Downloading ogb-1.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting omegaconf==2.3.0 (from -r requirements.txt (line 7))\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting optuna==3.5.0 (from -r requirements.txt (line 8))\n",
      "  Downloading optuna-3.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pandas==2.2.3 (from -r requirements.txt (line 9))\n",
      "  Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting parmap==1.7.0 (from -r requirements.txt (line 10))\n",
      "  Downloading parmap-1.7.0-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting Pillow==10.4.0 (from -r requirements.txt (line 11))\n",
      "  Downloading pillow-10.4.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting PyYAML==6.0.2 (from -r requirements.txt (line 12))\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting rdkit==2023.9.6 (from -r requirements.txt (line 13))\n",
      "  Downloading rdkit-2023.9.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.9 kB)\n",
      "Collecting scikit_learn==1.3.2 (from -r requirements.txt (line 14))\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy==1.14.1 (from -r requirements.txt (line 15))\n",
      "  Downloading scipy-1.14.1-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting streamlit==1.38.0 (from -r requirements.txt (line 16))\n",
      "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting streamlit_ketcher==0.0.1 (from -r requirements.txt (line 17))\n",
      "  Downloading streamlit_ketcher-0.0.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting torch==2.4.0 (from -r requirements.txt (line 18))\n",
      "  Downloading torch-2.4.0-cp310-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting pytorch_lightning (from -r requirements.txt (line 19))\n",
      "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting torch_geometric==2.6.1 (from -r requirements.txt (line 20))\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting tqdm==4.66.1 (from -r requirements.txt (line 21))\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tensorboard (from -r requirements.txt (line 22))\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 3)) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 3)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 3)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from matplotlib==3.9.2->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from ogb==1.2.0->-r requirements.txt (line 6)) (1.17.0)\n",
      "Collecting urllib3>=1.24.0 (from ogb==1.2.0->-r requirements.txt (line 6))\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0->-r requirements.txt (line 7))\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting alembic>=1.5.0 (from optuna==3.5.0->-r requirements.txt (line 8))\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna==3.5.0->-r requirements.txt (line 8))\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna==3.5.0->-r requirements.txt (line 8))\n",
      "  Downloading sqlalchemy-2.0.43-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from pandas==2.2.3->-r requirements.txt (line 9)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from pandas==2.2.3->-r requirements.txt (line 9)) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from scikit_learn==1.3.2->-r requirements.txt (line 14)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from scikit_learn==1.3.2->-r requirements.txt (line 14)) (3.6.0)\n",
      "Collecting altair<6,>=4.0 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib==3.9.2->-r requirements.txt (line 3))\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting requests<3,>=2.27 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from streamlit==1.38.0->-r requirements.txt (line 16)) (4.15.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from streamlit==1.38.0->-r requirements.txt (line 16)) (6.5.1)\n",
      "Collecting filelock (from torch==2.4.0->-r requirements.txt (line 18))\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting sympy (from torch==2.4.0->-r requirements.txt (line 18))\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jinja2 (from torch==2.4.0->-r requirements.txt (line 18))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch==2.4.0->-r requirements.txt (line 18))\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp (from torch_geometric==2.6.1->-r requirements.txt (line 20))\n",
      "  Downloading aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from torch_geometric==2.6.1->-r requirements.txt (line 20)) (7.0.0)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading narwhals-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.27->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Using cached charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.27->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.27->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit==1.38.0->-r requirements.txt (line 16)) (2.19.2)\n",
      "Requirement already satisfied: decorator in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 2)) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 2)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 2)) (3.0.52)\n",
      "Requirement already satisfied: stack_data in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from ipython->-r requirements.txt (line 2)) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->-r requirements.txt (line 2)) (0.2.14)\n",
      "Collecting torchmetrics>0.7.0 (from pytorch_lightning->-r requirements.txt (line 19))\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning->-r requirements.txt (line 19))\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 22))\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 22))\n",
      "  Downloading grpcio-1.75.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 22))\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 22)) (78.1.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 22))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 22))\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna==3.5.0->-r requirements.txt (line 8))\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting tomli (from alembic>=1.5.0->optuna==3.5.0->-r requirements.txt (line 8))\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->torch_geometric==2.6.1->-r requirements.txt (line 20))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->torch_geometric==2.6.1->-r requirements.txt (line 20))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch_geometric==2.6.1->-r requirements.txt (line 20))\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric==2.6.1->-r requirements.txt (line 20))\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric==2.6.1->-r requirements.txt (line 20))\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric==2.6.1->-r requirements.txt (line 20))\n",
      "  Downloading multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->torch_geometric==2.6.1->-r requirements.txt (line 20))\n",
      "  Downloading propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch_geometric==2.6.1->-r requirements.txt (line 20))\n",
      "  Downloading yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 2)) (0.8.5)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.4.0->-r requirements.txt (line 18))\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading rpds_py-0.27.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.38.0->-r requirements.txt (line 16))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from stack_data->ipython->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from stack_data->ipython->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (from stack_data->ipython->-r requirements.txt (line 2)) (0.2.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.0->-r requirements.txt (line 18))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading matplotlib-3.9.2-cp310-cp310-macosx_11_0_arm64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.1-cp310-cp310-macosx_11_0_arm64.whl (13.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ogb-1.2.0-py3-none-any.whl (45 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading parmap-1.7.0-py2.py3-none-any.whl (32 kB)\n",
      "Downloading pillow-10.4.0-cp310-cp310-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading rdkit-2023.9.6-cp310-cp310-macosx_11_0_arm64.whl (27.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.6/27.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp310-cp310-macosx_12_0_arm64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading streamlit_ketcher-0.0.1-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.0-cp310-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:00:28\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl (207 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl (468 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl (44 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl (89 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl (46 kB)\n",
      "Downloading grpcio-1.75.0-cp310-cp310-macosx_11_0_universal2.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading narwhals-2.5.0-py3-none-any.whl (407 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading pyarrow-21.0.0-cp310-cp310-macosx_12_0_arm64.whl (31.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp310-cp310-macosx_11_0_arm64.whl (353 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hUsing cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: lmdb, antlr4-python3-runtime\n",
      "\u001b[33m  DEPRECATION: Building 'lmdb' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'lmdb'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for lmdb (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lmdb: filename=lmdb-1.4.1-cp310-cp310-macosx_11_0_arm64.whl size=93814 sha256=814df92761517222408c7da738de80cbc4b2af1f2e36a0c5ec9e80dcbc4ef48d\n",
      "  Stored in directory: /Users/htdvu/Library/Caches/pip/wheels/e6/00/19/a038745f7b5c39772fad66e071042f5ecbefb215235c520e03\n",
      "\u001b[33m  DEPRECATION: Building 'antlr4-python3-runtime' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144590 sha256=c156ca8774bc9cc1ff17611500e645a6e269b42e09f0abbebae309121637fddf\n",
      "  Stored in directory: /Users/htdvu/Library/Caches/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built lmdb antlr4-python3-runtime\n",
      "Installing collected packages: parmap, mpmath, lmdb, antlr4-python3-runtime, urllib3, tqdm, tomli, toml, tensorboard-data-server, tenacity, sympy, sqlalchemy, smmap, rpds-py, PyYAML, pyarrow, protobuf, propcache, Pillow, packaging, numpy, networkx, narwhals, multidict, mdurl, MarkupSafe, markdown, idna, grpcio, fsspec, frozenlist, filelock, colorlog, click, charset_normalizer, certifi, cachetools, blinker, attrs, async-timeout, aiohappyeyeballs, absl-py, yarl, werkzeug, scipy, requests, referencing, rdkit, pandas, omegaconf, markdown-it-py, Mako, lightning-utilities, jinja2, gitdb, aiosignal, torch, tensorboard, scikit_learn, rich, pydeck, matplotlib, jsonschema-specifications, gitpython, alembic, aiohttp, torchmetrics, torch_geometric, optuna, ogb, jsonschema, pytorch_lightning, altair, streamlit, streamlit_ketcher\n",
      "\u001b[2K  Attempting uninstall: Pillow\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/75\u001b[0m [pyarrow]my]\n",
      "\u001b[2K    Found existing installation: pillow 11.3.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/75\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling pillow-11.3.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/75\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled pillow-11.3.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/75\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: packaging90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/75\u001b[0m [Pillow]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/75\u001b[0m [Pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/75\u001b[0m [Pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/75\u001b[0m [Pillow]\n",
      "\u001b[2K  Attempting uninstall: numpy90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/75\u001b[0m [Pillow]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/75\u001b[0m [Pillow]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/75\u001b[0m [Pillow]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/75\u001b[0m [Pillow]\n",
      "\u001b[2K  Attempting uninstall: scipy[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/75\u001b[0m [attrs]]s]\n",
      "\u001b[2K    Found existing installation: scipy 1.15.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/75\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling scipy-1.15.3:━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/75\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.390m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/75\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: rdkit━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/75\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: rdkit 2025.3.6━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/75\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling rdkit-2025.3.6:━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m47/75\u001b[0m [rdkit]\n",
      "\u001b[2K      Successfully uninstalled rdkit-2025.3.690m━━━━━━━━━━━━━━\u001b[0m \u001b[32m47/75\u001b[0m [rdkit]\n",
      "\u001b[2K  Attempting uninstall: pandas━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m47/75\u001b[0m [rdkit]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.290m━━━━━━━━━━━━━━\u001b[0m \u001b[32m47/75\u001b[0m [rdkit]\n",
      "\u001b[2K    Uninstalling pandas-2.3.2:━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/75\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.2\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/75\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: scikit_learn━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m57/75\u001b[0m [tensorboard]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.7.20m━━━━━━━━━\u001b[0m \u001b[32m57/75\u001b[0m [tensorboard]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.7.2:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m57/75\u001b[0m [tensorboard]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.7.2[90m━━━━━━━━━\u001b[0m \u001b[32m57/75\u001b[0m [tensorboard]\n",
      "\u001b[2K  Attempting uninstall: matplotlib━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m59/75\u001b[0m [rich]t_learn]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.6[90m━━━━━━━━\u001b[0m \u001b[32m59/75\u001b[0m [rich]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.6:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m59/75\u001b[0m [rich]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.6m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m61/75\u001b[0m [matplotlib]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75/75\u001b[0m [streamlit_ketcher]_ketcher]]ghtning]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Mako-1.3.10 MarkupSafe-3.0.2 Pillow-10.4.0 PyYAML-6.0.2 absl-py-2.3.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 alembic-1.16.5 altair-5.5.0 antlr4-python3-runtime-4.9.3 async-timeout-5.0.1 attrs-25.3.0 blinker-1.9.0 cachetools-5.5.2 certifi-2025.8.3 charset_normalizer-3.4.3 click-8.3.0 colorlog-6.9.0 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.9.0 gitdb-4.0.12 gitpython-3.1.45 grpcio-1.75.0 idna-3.10 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 lightning-utilities-0.15.2 lmdb-1.4.1 markdown-3.9 markdown-it-py-4.0.0 matplotlib-3.9.2 mdurl-0.1.2 mpmath-1.3.0 multidict-6.6.4 narwhals-2.5.0 networkx-2.8.8 numpy-1.24.1 ogb-1.2.0 omegaconf-2.3.0 optuna-3.5.0 packaging-24.2 pandas-2.2.3 parmap-1.7.0 propcache-0.3.2 protobuf-5.29.5 pyarrow-21.0.0 pydeck-0.9.1 pytorch_lightning-2.5.5 rdkit-2023.9.6 referencing-0.36.2 requests-2.32.5 rich-13.9.4 rpds-py-0.27.1 scikit_learn-1.3.2 scipy-1.14.1 smmap-5.0.2 sqlalchemy-2.0.43 streamlit-1.38.0 streamlit_ketcher-0.0.1 sympy-1.14.0 tenacity-8.5.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 toml-0.10.2 tomli-2.2.1 torch-2.4.0 torch_geometric-2.6.1 torchmetrics-1.8.2 tqdm-4.66.1 urllib3-2.5.0 werkzeug-3.1.3 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!cd FragNet && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b861ebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
      "Requirement already satisfied: torch-scatter in /Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e6a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/htdvu/Desktop/myLab/myLab-HDAC6-results/notebooks/FragNet\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: fragnet\n",
      "\u001b[33m  DEPRECATION: Building 'fragnet' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'fragnet'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for fragnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fragnet: filename=fragnet-0.1.0-py3-none-any.whl size=173215 sha256=c00bd337a1955b1118b0d310415b6766c63769f5bb3c12c83e4a0e805e31f334\n",
      "  Stored in directory: /private/var/folders/n6/jfk0f88s4wd2kc9whb2j35dw0000gn/T/pip-ephem-wheel-cache-7ncraeba/wheels/b5/86/cb/907b999daa669cb84ac97576a6864045d14cd6b2d150c2a1a7\n",
      "Successfully built fragnet\n",
      "Installing collected packages: fragnet\n",
      "Successfully installed fragnet-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!cd FragNet && pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c75c44",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3aa9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/htdvu/Desktop/myLab/myLab-HDAC6-results/notebooks/FragNet/fragnet\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# enter the FragNet directory\n",
    "os.chdir(\"Fragnet/fragnet\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d57b9da",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "FragNet uses [ESOL](https://huggingface.co/datasets/scikit-fingerprints/MoleculeNet_ESOL) dataset from [Uni-Mol](https://github.com/deepmodeling/Uni-Mol/tree/main/unimol). \n",
    "\n",
    "ESOL is a dataset for predicting water solubility of molecules. The dataset contains 1128 molecules with their SMILES representations and corresponding solubility values (logS). The dataset is split into training, validation, and test sets with a ratio of 80:10:10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e0aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p finetune_data/moleculenet/esol/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b44a14e",
   "metadata": {},
   "source": [
    "### Installation and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c20f0395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 96699  100 96699    0     0  83929      0  0:00:01  0:00:01 --:--:-- 83940\n"
     ]
    }
   ],
   "source": [
    "!curl -o finetune_data/moleculenet/esol/raw/delaney-processed.csv https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4ac86",
   "metadata": {},
   "source": [
    "#### Create pretrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd477eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:16<00:00, 59.67it/s]\n",
      "16.771543741226196\n",
      "0.004193782806396484\n",
      "998it [00:12, 82.06it/s] \n",
      "(1000, 10)\n",
      "100%|█████████████████████████████████████████| 128/128 [00:02<00:00, 63.08it/s]\n",
      "2.029557943344116\n",
      "0.0007376670837402344\n",
      "128it [00:00, 328160.70it/s]\n",
      "(128, 10)\n"
     ]
    }
   ],
   "source": [
    "!python data_create/create_pretrain_datasets.py --save_path pretrain_data/esol --data_type exp1s --maxiters 500 --raw_data_path finetune_data/moleculenet/esol/raw/delaney-processed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16064684",
   "metadata": {},
   "source": [
    "#### Create finetune data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761d0df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.use_genes:  0\n",
      "args.multi_conf_data:  0\n",
      "Processing...\n",
      "Done!\n",
      "100%|█████████████████████████████████████████| 902/902 [00:11<00:00, 77.67it/s]\n",
      "11.624279022216797\n",
      "0.0052988529205322266\n",
      "902it [00:04, 216.35it/s]\n",
      "100%|█████████████████████████████████████████| 113/113 [00:02<00:00, 49.03it/s]\n",
      "2.3047871589660645\n",
      "0.000782012939453125\n",
      "113it [00:00, 358514.64it/s]\n",
      "100%|█████████████████████████████████████████| 113/113 [00:02<00:00, 42.47it/s]\n",
      "2.661094903945923\n",
      "0.0012328624725341797\n",
      "113it [00:00, 4282.45it/s]\n"
     ]
    }
   ],
   "source": [
    "!python data_create/create_finetune_datasets.py --dataset_name moleculenet --dataset_subset esol --use_molebert True --output_dir finetune_data/moleculenet_exp1s --data_dir finetune_data/moleculenet --data_type exp1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee6574",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0e3bc",
   "metadata": {},
   "source": [
    "### Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9610cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pt_1000_1999.pkl', 'pt_0_999.pkl']\n",
      "/Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "number of data points:  1126\n",
      "4.51919673155232 45.174026894358406\n",
      "Validation loss decreased (inf --> 45.174027).  Saving model ...\n",
      "4.110702469459526 45.04167242809734\n",
      "Validation loss decreased (45.174027 --> 45.041672).  Saving model ...\n",
      "4.1708844590634255 44.89939245713496\n",
      "Validation loss decreased (45.041672 --> 44.899392).  Saving model ...\n",
      "4.227812365035785 44.735891696626105\n",
      "Validation loss decreased (44.899392 --> 44.735892).  Saving model ...\n",
      "3.8260875223654986 44.545755842090706\n",
      "Validation loss decreased (44.735892 --> 44.545756).  Saving model ...\n",
      "4.3255693561821325 44.316717367256636\n",
      "Validation loss decreased (44.545756 --> 44.316717).  Saving model ...\n",
      "3.760219442173618 44.03733839186947\n",
      "Validation loss decreased (44.316717 --> 44.037338).  Saving model ...\n",
      "3.9659191255861304 43.699974937776545\n",
      "Validation loss decreased (44.037338 --> 43.699975).  Saving model ...\n",
      "4.2897296088351435 43.27851043971239\n",
      "Validation loss decreased (43.699975 --> 43.278510).  Saving model ...\n",
      "3.986909917170533 42.75399699253319\n",
      "Validation loss decreased (43.278510 --> 42.753997).  Saving model ...\n",
      "3.8460157117627096 42.08394548534292\n",
      "Validation loss decreased (42.753997 --> 42.083945).  Saving model ...\n",
      "4.002198470662636 41.20565714878319\n",
      "Validation loss decreased (42.083945 --> 41.205657).  Saving model ...\n",
      "4.139112436759625 40.104327986725664\n",
      "Validation loss decreased (41.205657 --> 40.104328).  Saving model ...\n",
      "3.7659841012154494 38.80276894358407\n",
      "Validation loss decreased (40.104328 --> 38.802769).  Saving model ...\n",
      "3.8419894400141907 37.44988851631637\n",
      "Validation loss decreased (38.802769 --> 37.449889).  Saving model ...\n",
      "3.796129563718534 36.291715638827434\n",
      "Validation loss decreased (37.449889 --> 36.291716).  Saving model ...\n",
      "3.614575701428307 35.68345331512721\n",
      "Validation loss decreased (36.291716 --> 35.683453).  Saving model ...\n",
      "4.0712750840634255 35.34044870022124\n",
      "Validation loss decreased (35.683453 --> 35.340449).  Saving model ...\n",
      "4.202067458970879 35.191598537748895\n",
      "Validation loss decreased (35.340449 --> 35.191599).  Saving model ...\n",
      "4.014818347806639 34.950281733960175\n",
      "Validation loss decreased (35.191599 --> 34.950282).  Saving model ...\n",
      "3.8432593086747286 34.6909201292865\n",
      "Validation loss decreased (34.950282 --> 34.690920).  Saving model ...\n",
      "3.9204747462672755 34.55489491150443\n",
      "Validation loss decreased (34.690920 --> 34.554895).  Saving model ...\n",
      "3.3894464731922507 34.31079965777102\n",
      "Validation loss decreased (34.554895 --> 34.310800).  Saving model ...\n",
      "3.8790877286679417 33.90651574599004\n",
      "Validation loss decreased (34.310800 --> 33.906516).  Saving model ...\n",
      "3.6691282372131044 33.62864050400996\n",
      "Validation loss decreased (33.906516 --> 33.628641).  Saving model ...\n",
      "3.544364665597236 33.55160225387168\n",
      "Validation loss decreased (33.628641 --> 33.551602).  Saving model ...\n",
      "3.5436100710297382 33.42254908738938\n",
      "Validation loss decreased (33.551602 --> 33.422549).  Saving model ...\n",
      "3.6813576821631293 32.89619702364491\n",
      "Validation loss decreased (33.422549 --> 32.896197).  Saving model ...\n",
      "3.5047208554417573 32.62852167450221\n",
      "Validation loss decreased (32.896197 --> 32.628522).  Saving model ...\n",
      "3.8273571500185093 32.6207048534292\n",
      "Validation loss decreased (32.628522 --> 32.620705).  Saving model ...\n",
      "3.3860841771810217 32.485744780143804\n",
      "Validation loss decreased (32.620705 --> 32.485745).  Saving model ...\n",
      "3.558476138326752 32.1734845996958\n",
      "Validation loss decreased (32.485745 --> 32.173485).  Saving model ...\n",
      "3.4146761051641166 31.968825618777654\n",
      "Validation loss decreased (32.173485 --> 31.968826).  Saving model ...\n",
      "3.367877022535168 31.913909101908185\n",
      "Validation loss decreased (31.968826 --> 31.913909).  Saving model ...\n",
      "3.6800820293219396 31.83702208932522\n",
      "Validation loss decreased (31.913909 --> 31.837022).  Saving model ...\n",
      "3.8382417729670535 31.424601597068584\n",
      "Validation loss decreased (31.837022 --> 31.424602).  Saving model ...\n",
      "3.7132892514499014 31.457547618224556\n",
      "EarlyStopping counter: 1 out of 200\n",
      "3.493255645360316 31.408248496266594\n",
      "Validation loss decreased (31.424602 --> 31.408248).  Saving model ...\n",
      "3.4094980584433614 30.814412074806416\n",
      "Validation loss decreased (31.408248 --> 30.814412).  Saving model ...\n",
      "3.1299421003516783 30.72525753595133\n",
      "Validation loss decreased (30.814412 --> 30.725258).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "!python train/pretrain/pretrain_gat2.py --config exps/pt/unimol_exp1s4/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9c8e7",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c770bf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gat2\n",
      "using FTHead3\n",
      "loaded from gat2\n",
      "/Users/htdvu/Desktop/myLab/myLab-HDAC6-results/notebooks/FragNet/fragnet/train/finetune/finetune_gat2.py:225: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  modelpt.load_state_dict(torch.load(pt_chkpoint_name, map_location=torch.device(device)))\n",
      "loading pretrained weights from exps/pt/unimol_exp1s4/pt.pt\n",
      "weights loaded\n",
      "/Users/htdvu/miniconda3/envs/mylab-hdac6/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "epoch:  0 0.30238543777931026 2.5664\n",
      "Validation loss decreased (inf --> 2.566400).  Saving model ...\n",
      "epoch:  1 0.16335537124367353 2.5093226\n",
      "Validation loss decreased (2.566400 --> 2.509323).  Saving model ...\n",
      "epoch:  2 0.15200962222071815 2.7553039\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  3 0.1427825691298212 2.7583818\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  4 0.14453264383677633 2.3454442\n",
      "Validation loss decreased (2.509323 --> 2.345444).  Saving model ...\n",
      "epoch:  5 0.14183308412124734 2.4641392\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  6 0.13417095712441826 2.186009\n",
      "Validation loss decreased (2.345444 --> 2.186009).  Saving model ...\n",
      "epoch:  7 0.12494376295157388 2.3316157\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  8 0.12250748052036683 2.5061827\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  9 0.11849533526966154 2.3739502\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  10 0.10805949238345787 2.1630404\n",
      "Validation loss decreased (2.186009 --> 2.163040).  Saving model ...\n",
      "epoch:  11 0.0986707897778361 2.1908147\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  12 0.08971576567764028 2.6159241\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  13 0.11312623351746282 2.2825763\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  14 0.0865690963231275 2.1359472\n",
      "Validation loss decreased (2.163040 --> 2.135947).  Saving model ...\n",
      "epoch:  15 0.08841617061795787 2.339343\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  16 0.08307986407480854 2.4433174\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  17 0.08510402611512567 2.0973322\n",
      "Validation loss decreased (2.135947 --> 2.097332).  Saving model ...\n",
      "epoch:  18 0.0856523191981728 2.022533\n",
      "Validation loss decreased (2.097332 --> 2.022533).  Saving model ...\n",
      "epoch:  19 0.08419398299341985 2.0457687\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  20 0.07882541312346701 2.4173706\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  21 0.08273566059949922 2.4766538\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  22 0.07546839527703178 2.3562825\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  23 0.07365174059592963 2.099551\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  24 0.07175673045498833 2.0840342\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  25 0.07284349322054709 2.2289705\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  26 0.07089295633087665 2.0572076\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  27 0.07317748807882787 2.21679\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  28 0.06981533161155928 1.9227071\n",
      "Validation loss decreased (2.022533 --> 1.922707).  Saving model ...\n",
      "epoch:  29 0.06797484600887595 2.2559912\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  30 0.0694253000940822 2.5612216\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  31 0.06730839841381674 1.9730232\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  32 0.07216497575100139 2.0793397\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  33 0.06572077686004259 1.7542775\n",
      "Validation loss decreased (1.922707 --> 1.754277).  Saving model ...\n",
      "epoch:  34 0.06557162182029758 1.8622484\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  35 0.06790918369515243 1.884862\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  36 0.06260572472987841 2.3292587\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  37 0.061959685877527204 2.0821795\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  38 0.06155246453248212 2.1457965\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  39 0.061576038731175356 1.7728293\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  40 0.06488552669728145 1.7606328\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  41 0.06222756626600701 1.6831406\n",
      "Validation loss decreased (1.754277 --> 1.683141).  Saving model ...\n",
      "epoch:  42 0.057374488421924365 2.0454075\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  43 0.058285016872137455 1.8301767\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  44 0.05667770672135237 2.1879637\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  45 0.0640946150222533 1.5843914\n",
      "Validation loss decreased (1.683141 --> 1.584391).  Saving model ...\n",
      "epoch:  46 0.05605348158305606 1.9420112\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  47 0.058297115392536916 1.7680434\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  48 0.055914291422277225 1.9635553\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  49 0.056007143993864035 1.6625043\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  50 0.05706564553428912 1.881142\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  51 0.05618278933337945 1.9073944\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  52 0.056320805837732725 1.9666675\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  53 0.0533488552909997 1.9591556\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  54 0.060188495200912066 1.7266428\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  55 0.056284560795105215 2.2049236\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  56 0.056048117098945735 2.0455797\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  57 0.051184803974337695 1.4994622\n",
      "Validation loss decreased (1.584391 --> 1.499462).  Saving model ...\n",
      "epoch:  58 0.0541538141188759 1.3441697\n",
      "Validation loss decreased (1.499462 --> 1.344170).  Saving model ...\n",
      "epoch:  59 0.05260958269800157 1.8056747\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  60 0.05288982584642994 1.4477758\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  61 0.04804244189793678 1.4738569\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  62 0.04839225030791204 1.2993089\n",
      "Validation loss decreased (1.344170 --> 1.299309).  Saving model ...\n",
      "epoch:  63 0.0539531050592727 1.2952987\n",
      "Validation loss decreased (1.299309 --> 1.295299).  Saving model ...\n",
      "epoch:  64 0.05317184500842295 1.4321622\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  65 0.045969170536804625 1.4210753\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  66 0.04841256386160586 1.5453664\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  67 0.04888716644035475 1.2024622\n",
      "Validation loss decreased (1.295299 --> 1.202462).  Saving model ...\n",
      "epoch:  68 0.05183997497524232 1.5274045\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  69 0.047044766674483166 1.4314207\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  70 0.041116208069340354 1.1466513\n",
      "Validation loss decreased (1.202462 --> 1.146651).  Saving model ...\n",
      "epoch:  71 0.043330577253766704 1.2839628\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  72 0.050334122370589866 1.5311215\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  73 0.04791458018801429 1.298505\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  74 0.047014432577230446 1.3395184\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  75 0.043246889325837604 1.3616312\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  76 0.04380206152499383 1.3028727\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  77 0.04025942605905681 1.4859754\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  78 0.05065236546247867 1.2407335\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  79 0.04879519948013077 1.6387511\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  80 0.04506312728655047 1.3982464\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  81 0.04540991705497458 1.3994881\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  82 0.04492311101993277 1.6946694\n",
      "EarlyStopping counter: 12 out of 100\n",
      "epoch:  83 0.040909979087682624 1.8185519\n",
      "EarlyStopping counter: 13 out of 100\n",
      "epoch:  84 0.04557426706650305 1.2625813\n",
      "EarlyStopping counter: 14 out of 100\n",
      "epoch:  85 0.04371429553581711 1.433229\n",
      "EarlyStopping counter: 15 out of 100\n",
      "epoch:  86 0.04382218291648476 1.5196342\n",
      "EarlyStopping counter: 16 out of 100\n",
      "epoch:  87 0.04209109375918255 1.1553239\n",
      "EarlyStopping counter: 17 out of 100\n",
      "epoch:  88 0.041348382681938606 1.4344665\n",
      "EarlyStopping counter: 18 out of 100\n",
      "epoch:  89 0.03884283808408978 1.497544\n",
      "EarlyStopping counter: 19 out of 100\n",
      "epoch:  90 0.040691786092559405 1.2052844\n",
      "EarlyStopping counter: 20 out of 100\n",
      "epoch:  91 0.04154547718570396 1.103144\n",
      "Validation loss decreased (1.146651 --> 1.103144).  Saving model ...\n",
      "epoch:  92 0.04025923077454852 1.5570992\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  93 0.039575304579972694 1.323357\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  94 0.04109801974833144 1.4749207\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  95 0.03778636358067096 1.3506427\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  96 0.03744277097036992 1.4275353\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  97 0.03748937299735266 1.1818798\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  98 0.040239538823950316 1.2359693\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  99 0.03851263859451742 1.6235385\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  100 0.03926747330276506 1.4156207\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  101 0.04206066431597437 1.4856204\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  102 0.043805614378129826 2.2671998\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  103 0.03672447447105416 1.5127331\n",
      "EarlyStopping counter: 12 out of 100\n",
      "epoch:  104 0.03412883241398636 1.3113648\n",
      "EarlyStopping counter: 13 out of 100\n",
      "epoch:  105 0.04073032920151751 1.1914691\n",
      "EarlyStopping counter: 14 out of 100\n",
      "epoch:  106 0.03562652516259322 1.1860584\n",
      "EarlyStopping counter: 15 out of 100\n",
      "epoch:  107 0.03640752429444087 1.4206984\n",
      "EarlyStopping counter: 16 out of 100\n",
      "epoch:  108 0.03741587625771034 1.568739\n",
      "EarlyStopping counter: 17 out of 100\n",
      "epoch:  109 0.042286852544004265 1.788402\n",
      "EarlyStopping counter: 18 out of 100\n",
      "epoch:  110 0.04041086773319942 1.1528594\n",
      "EarlyStopping counter: 19 out of 100\n",
      "epoch:  111 0.03444815081794087 1.1918249\n",
      "EarlyStopping counter: 20 out of 100\n",
      "epoch:  112 0.03800696088310884 1.292551\n",
      "EarlyStopping counter: 21 out of 100\n",
      "epoch:  113 0.037212237467919115 1.6852999\n",
      "EarlyStopping counter: 22 out of 100\n",
      "epoch:  114 0.03559176171169577 1.4048291\n",
      "EarlyStopping counter: 23 out of 100\n",
      "epoch:  115 0.035444037579908605 1.9516687\n",
      "EarlyStopping counter: 24 out of 100\n",
      "epoch:  116 0.04041567272991933 1.493355\n",
      "EarlyStopping counter: 25 out of 100\n",
      "epoch:  117 0.03374738990434522 1.8448544\n",
      "EarlyStopping counter: 26 out of 100\n",
      "epoch:  118 0.03618773711461186 1.3308055\n",
      "EarlyStopping counter: 27 out of 100\n",
      "epoch:  119 0.03494046043662433 1.1703111\n",
      "EarlyStopping counter: 28 out of 100\n",
      "epoch:  120 0.03525968791375932 1.7624264\n",
      "EarlyStopping counter: 29 out of 100\n",
      "epoch:  121 0.03541257209299409 1.8546689\n",
      "EarlyStopping counter: 30 out of 100\n",
      "epoch:  122 0.032187510422222364 1.0991931\n",
      "Validation loss decreased (1.103144 --> 1.099193).  Saving model ...\n",
      "epoch:  123 0.03442719033578547 1.4701656\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  124 0.03296793825478353 1.3189993\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  125 0.03353792650340137 1.1463499\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  126 0.039022071497667656 2.0859592\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  127 0.03525466113423561 1.3822509\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  128 0.03268022726221782 1.1500435\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  129 0.03263140648206956 1.1789236\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  130 0.03300613531648716 1.7114172\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  131 0.02993207613208606 1.5342926\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  132 0.031236483292146164 1.4731088\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  133 0.03270810161884503 1.339633\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  134 0.0319109757135554 1.1775796\n",
      "EarlyStopping counter: 12 out of 100\n",
      "epoch:  135 0.030701249424872006 1.1836224\n",
      "EarlyStopping counter: 13 out of 100\n",
      "epoch:  136 0.02981358678999074 1.6639533\n",
      "EarlyStopping counter: 14 out of 100\n",
      "epoch:  137 0.03399046016505975 1.3403088\n",
      "EarlyStopping counter: 15 out of 100\n",
      "epoch:  138 0.03273884456464298 1.0723976\n",
      "Validation loss decreased (1.099193 --> 1.072398).  Saving model ...\n",
      "epoch:  139 0.034353710364079526 1.09868\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  140 0.029704307323681012 1.3849725\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  141 0.03334392531219449 1.5050077\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  142 0.029706117021799615 1.6389157\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  143 0.030285201636359855 1.1078961\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  144 0.030039483900212924 1.8221313\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  145 0.03391039194725041 1.2671248\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  146 0.03144646229474349 1.5083677\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  147 0.02745806778514729 1.4728386\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  148 0.030417774525159213 2.1640556\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  149 0.03331092760759817 1.330297\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  150 0.029546533085554508 1.3455744\n",
      "EarlyStopping counter: 12 out of 100\n",
      "epoch:  151 0.029023854636035844 1.0469381\n",
      "Validation loss decreased (1.072398 --> 1.046938).  Saving model ...\n",
      "epoch:  152 0.031016343035745516 1.1264688\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  153 0.030346729571697716 1.2069771\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  154 0.029415571075056716 1.3081081\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  155 0.0278614591683226 1.383352\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  156 0.027330587227764786 1.3480556\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  157 0.030274296778268667 1.8100094\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  158 0.03500162028684849 1.2712954\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  159 0.032283240123889397 1.5005422\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  160 0.02622684169800213 1.2212664\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  161 0.031705208948736976 1.1396704\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  162 0.03240093268338434 1.4285744\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  163 0.027940308076315073 1.2534192\n",
      "EarlyStopping counter: 12 out of 100\n",
      "epoch:  164 0.02780809854787099 1.27237\n",
      "EarlyStopping counter: 13 out of 100\n",
      "epoch:  165 0.029608916879493224 1.1167988\n",
      "EarlyStopping counter: 14 out of 100\n",
      "epoch:  166 0.02940388243571089 1.1868833\n",
      "EarlyStopping counter: 15 out of 100\n",
      "epoch:  167 0.027661644393152777 1.2476188\n",
      "EarlyStopping counter: 16 out of 100\n",
      "epoch:  168 0.030070775182310598 1.217152\n",
      "EarlyStopping counter: 17 out of 100\n",
      "epoch:  169 0.027570164124347155 1.3773565\n",
      "EarlyStopping counter: 18 out of 100\n",
      "epoch:  170 0.02820203244322684 1.768046\n",
      "EarlyStopping counter: 19 out of 100\n",
      "epoch:  171 0.026825118066532386 1.8040584\n",
      "EarlyStopping counter: 20 out of 100\n",
      "epoch:  172 0.027549715039471036 1.4522246\n",
      "EarlyStopping counter: 21 out of 100\n",
      "epoch:  173 0.025466965333849786 1.0741886\n",
      "EarlyStopping counter: 22 out of 100\n",
      "epoch:  174 0.025650148067268196 1.1892625\n",
      "EarlyStopping counter: 23 out of 100\n",
      "epoch:  175 0.028900154934423727 1.127691\n",
      "EarlyStopping counter: 24 out of 100\n",
      "epoch:  176 0.02772609407945377 1.5404794\n",
      "EarlyStopping counter: 25 out of 100\n",
      "epoch:  177 0.026887586534419767 1.1686788\n",
      "EarlyStopping counter: 26 out of 100\n",
      "epoch:  178 0.026159528832874382 1.4698219\n",
      "EarlyStopping counter: 27 out of 100\n",
      "epoch:  179 0.027597745132948503 1.1232438\n",
      "EarlyStopping counter: 28 out of 100\n",
      "epoch:  180 0.025305733266400128 1.2508289\n",
      "EarlyStopping counter: 29 out of 100\n",
      "epoch:  181 0.027595492026163574 1.2096895\n",
      "EarlyStopping counter: 30 out of 100\n",
      "epoch:  182 0.02703102433562543 1.6269888\n",
      "EarlyStopping counter: 31 out of 100\n",
      "epoch:  183 0.025464629898975272 1.3933002\n",
      "EarlyStopping counter: 32 out of 100\n",
      "epoch:  184 0.025663784628696822 1.4996837\n",
      "EarlyStopping counter: 33 out of 100\n",
      "epoch:  185 0.024787891011875115 1.7413948\n",
      "EarlyStopping counter: 34 out of 100\n",
      "epoch:  186 0.03030228594982968 1.1448443\n",
      "EarlyStopping counter: 35 out of 100\n",
      "epoch:  187 0.029650808999649437 1.5039535\n",
      "EarlyStopping counter: 36 out of 100\n",
      "epoch:  188 0.025555395448947957 1.929988\n",
      "EarlyStopping counter: 37 out of 100\n",
      "epoch:  189 0.024800013701231145 1.3428918\n",
      "EarlyStopping counter: 38 out of 100\n",
      "epoch:  190 0.02775360453882133 1.1246989\n",
      "EarlyStopping counter: 39 out of 100\n",
      "epoch:  191 0.02594562895810789 1.440861\n",
      "EarlyStopping counter: 40 out of 100\n",
      "epoch:  192 0.025527321859500362 1.3550142\n",
      "EarlyStopping counter: 41 out of 100\n",
      "epoch:  193 0.02372157934664887 1.2492944\n",
      "EarlyStopping counter: 42 out of 100\n",
      "epoch:  194 0.026687588691381024 1.3767707\n",
      "EarlyStopping counter: 43 out of 100\n",
      "epoch:  195 0.028735203565224313 1.2931212\n",
      "EarlyStopping counter: 44 out of 100\n",
      "epoch:  196 0.02371798717559309 1.3309004\n",
      "EarlyStopping counter: 45 out of 100\n",
      "epoch:  197 0.024300554664000176 1.065481\n",
      "EarlyStopping counter: 46 out of 100\n",
      "epoch:  198 0.024473341029063032 1.021162\n",
      "Validation loss decreased (1.046938 --> 1.021162).  Saving model ...\n",
      "epoch:  199 0.02493718230142826 1.2151558\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  200 0.025675051740294285 1.2022924\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  201 0.021827891237719887 1.3310728\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  202 0.023360752015314717 1.3240685\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  203 0.023893555143059225 1.6834326\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  204 0.02262348182780251 1.163875\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  205 0.026703044094822624 1.028518\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  206 0.024704869398785273 1.4626383\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  207 0.023380040684652964 1.3447175\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  208 0.025008761763837015 1.3630475\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  209 0.02441348968086116 1.5285591\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  210 0.023163395997822418 1.4005812\n",
      "EarlyStopping counter: 12 out of 100\n",
      "epoch:  211 0.02799981667302929 1.2423565\n",
      "EarlyStopping counter: 13 out of 100\n",
      "epoch:  212 0.023175566422106685 1.3851697\n",
      "EarlyStopping counter: 14 out of 100\n",
      "epoch:  213 0.023537032628336927 1.0440544\n",
      "EarlyStopping counter: 15 out of 100\n",
      "epoch:  214 0.023340640502864135 0.98430103\n",
      "Validation loss decreased (1.021162 --> 0.984301).  Saving model ...\n",
      "epoch:  215 0.024524157879225694 1.4709485\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  216 0.02563951273516911 1.49705\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  217 0.024194109375421328 1.2524153\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  218 0.025779451687558 1.2900186\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  219 0.02116619308216873 1.4433495\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  220 0.023397360434817632 1.0504392\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  221 0.022021932481992537 1.2567599\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  222 0.022942679056571488 1.4576911\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  223 0.024003829418819917 1.4841493\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  224 0.022368886551412934 1.3455217\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  225 0.021474858006656567 1.1480049\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  226 0.024056491287148447 1.3386036\n",
      "EarlyStopping counter: 12 out of 100\n",
      "epoch:  227 0.024038246525100487 1.3810961\n",
      "EarlyStopping counter: 13 out of 100\n",
      "epoch:  228 0.02621660224614281 1.5448989\n",
      "EarlyStopping counter: 14 out of 100\n",
      "epoch:  229 0.02010054493987904 1.522074\n",
      "EarlyStopping counter: 15 out of 100\n",
      "epoch:  230 0.023126122907233607 1.1326902\n",
      "EarlyStopping counter: 16 out of 100\n",
      "epoch:  231 0.02211489646536548 1.182021\n",
      "EarlyStopping counter: 17 out of 100\n",
      "epoch:  232 0.022036311623460703 1.2099165\n",
      "EarlyStopping counter: 18 out of 100\n",
      "epoch:  233 0.020566987786483342 1.0564394\n",
      "EarlyStopping counter: 19 out of 100\n",
      "epoch:  234 0.02227093876564582 1.1122322\n",
      "EarlyStopping counter: 20 out of 100\n",
      "epoch:  235 0.021536805495586734 1.2976949\n",
      "EarlyStopping counter: 21 out of 100\n",
      "epoch:  236 0.01913303445752074 1.0690118\n",
      "EarlyStopping counter: 22 out of 100\n",
      "epoch:  237 0.022331419539226925 1.034276\n",
      "EarlyStopping counter: 23 out of 100\n",
      "epoch:  238 0.02151752129494483 1.4093711\n",
      "EarlyStopping counter: 24 out of 100\n",
      "epoch:  239 0.02483054149705925 1.4499441\n",
      "EarlyStopping counter: 25 out of 100\n",
      "epoch:  240 0.021359590470724783 1.215261\n",
      "EarlyStopping counter: 26 out of 100\n",
      "epoch:  241 0.019116147493576 0.9901843\n",
      "EarlyStopping counter: 27 out of 100\n",
      "epoch:  242 0.0232036435055627 1.3022748\n",
      "EarlyStopping counter: 28 out of 100\n",
      "epoch:  243 0.022765569091504005 1.1696147\n",
      "EarlyStopping counter: 29 out of 100\n",
      "epoch:  244 0.0219799543167165 1.2490134\n",
      "EarlyStopping counter: 30 out of 100\n",
      "epoch:  245 0.019362676583081814 1.1698202\n",
      "EarlyStopping counter: 31 out of 100\n",
      "epoch:  246 0.020654514745835982 1.3400917\n",
      "EarlyStopping counter: 32 out of 100\n",
      "epoch:  247 0.023191208858249455 1.2319708\n",
      "EarlyStopping counter: 33 out of 100\n",
      "epoch:  248 0.02230534482821657 1.297295\n",
      "EarlyStopping counter: 34 out of 100\n",
      "epoch:  249 0.023431051101229936 1.2757785\n",
      "EarlyStopping counter: 35 out of 100\n",
      "epoch:  250 0.02197780734353478 1.3912508\n",
      "EarlyStopping counter: 36 out of 100\n",
      "epoch:  251 0.01923896211659961 1.0049801\n",
      "EarlyStopping counter: 37 out of 100\n",
      "epoch:  252 0.01978954023572135 1.3238904\n",
      "EarlyStopping counter: 38 out of 100\n",
      "epoch:  253 0.019606074446320797 1.4779407\n",
      "EarlyStopping counter: 39 out of 100\n",
      "epoch:  254 0.01731335030591937 1.146153\n",
      "EarlyStopping counter: 40 out of 100\n",
      "epoch:  255 0.02111266210609159 1.1018126\n",
      "EarlyStopping counter: 41 out of 100\n",
      "epoch:  256 0.02027602936502571 1.2821822\n",
      "EarlyStopping counter: 42 out of 100\n",
      "epoch:  257 0.02043693587844758 1.2892703\n",
      "EarlyStopping counter: 43 out of 100\n",
      "epoch:  258 0.020774164346527894 1.1565423\n",
      "EarlyStopping counter: 44 out of 100\n",
      "epoch:  259 0.020700329976639568 1.2708488\n",
      "EarlyStopping counter: 45 out of 100\n",
      "epoch:  260 0.01976040948983571 1.1239487\n",
      "EarlyStopping counter: 46 out of 100\n",
      "epoch:  261 0.01992619394463076 1.2685394\n",
      "EarlyStopping counter: 47 out of 100\n",
      "epoch:  262 0.019142642559405176 1.1771951\n",
      "EarlyStopping counter: 48 out of 100\n",
      "epoch:  263 0.0202205221430954 1.1910582\n",
      "EarlyStopping counter: 49 out of 100\n",
      "epoch:  264 0.018242576211162258 1.219465\n",
      "EarlyStopping counter: 50 out of 100\n",
      "epoch:  265 0.01915133887377388 1.2975924\n",
      "EarlyStopping counter: 51 out of 100\n",
      "epoch:  266 0.01954985330678407 1.5860034\n",
      "EarlyStopping counter: 52 out of 100\n",
      "epoch:  267 0.019544489128296233 1.1020299\n",
      "EarlyStopping counter: 53 out of 100\n",
      "epoch:  268 0.018526950566110485 1.4973276\n",
      "EarlyStopping counter: 54 out of 100\n",
      "epoch:  269 0.01907644092937531 1.1946383\n",
      "EarlyStopping counter: 55 out of 100\n",
      "epoch:  270 0.020882726690325135 1.1413686\n",
      "EarlyStopping counter: 56 out of 100\n",
      "epoch:  271 0.020730666328890625 1.1638974\n",
      "EarlyStopping counter: 57 out of 100\n",
      "epoch:  272 0.01798696194810508 1.2575955\n",
      "EarlyStopping counter: 58 out of 100\n",
      "epoch:  273 0.01923718932033114 1.0568438\n",
      "EarlyStopping counter: 59 out of 100\n",
      "epoch:  274 0.019891948928589833 1.3280922\n",
      "EarlyStopping counter: 60 out of 100\n",
      "epoch:  275 0.017528349669968208 1.1577334\n",
      "EarlyStopping counter: 61 out of 100\n",
      "epoch:  276 0.019302176860906597 1.4323244\n",
      "EarlyStopping counter: 62 out of 100\n",
      "epoch:  277 0.017801744289316253 1.1325629\n",
      "EarlyStopping counter: 63 out of 100\n",
      "epoch:  278 0.016426233331076057 1.1412573\n",
      "EarlyStopping counter: 64 out of 100\n",
      "epoch:  279 0.017075660962718817 1.0530242\n",
      "EarlyStopping counter: 65 out of 100\n",
      "epoch:  280 0.019760138534851982 1.186538\n",
      "EarlyStopping counter: 66 out of 100\n",
      "epoch:  281 0.017813390178684385 1.0004163\n",
      "EarlyStopping counter: 67 out of 100\n",
      "epoch:  282 0.020349169971871535 1.3633751\n",
      "EarlyStopping counter: 68 out of 100\n",
      "epoch:  283 0.019792665547780083 0.9902465\n",
      "EarlyStopping counter: 69 out of 100\n",
      "epoch:  284 0.017238038160452027 1.1229987\n",
      "EarlyStopping counter: 70 out of 100\n",
      "epoch:  285 0.016647464065025756 1.2973655\n",
      "EarlyStopping counter: 71 out of 100\n",
      "epoch:  286 0.017987592496853444 1.3123122\n",
      "EarlyStopping counter: 72 out of 100\n",
      "epoch:  287 0.017592706769176174 1.3580517\n",
      "EarlyStopping counter: 73 out of 100\n",
      "epoch:  288 0.019980357038869034 1.7382694\n",
      "EarlyStopping counter: 74 out of 100\n",
      "epoch:  289 0.019710027102686614 1.5531613\n",
      "EarlyStopping counter: 75 out of 100\n",
      "epoch:  290 0.0182090576597698 1.0376393\n",
      "EarlyStopping counter: 76 out of 100\n",
      "epoch:  291 0.01828771429817851 1.2789305\n",
      "EarlyStopping counter: 77 out of 100\n",
      "epoch:  292 0.016664551500800973 1.4726629\n",
      "EarlyStopping counter: 78 out of 100\n",
      "epoch:  293 0.018160639681797597 1.2951365\n",
      "EarlyStopping counter: 79 out of 100\n",
      "epoch:  294 0.019116287807337196 1.3846482\n",
      "EarlyStopping counter: 80 out of 100\n",
      "epoch:  295 0.018438466867956513 1.3459643\n",
      "EarlyStopping counter: 81 out of 100\n",
      "epoch:  296 0.016191318622912114 1.0540613\n",
      "EarlyStopping counter: 82 out of 100\n",
      "epoch:  297 0.017092198290409904 1.2361095\n",
      "EarlyStopping counter: 83 out of 100\n",
      "epoch:  298 0.020235615995136437 1.205772\n",
      "EarlyStopping counter: 84 out of 100\n",
      "epoch:  299 0.017657411675032913 1.4631996\n",
      "EarlyStopping counter: 85 out of 100\n",
      "epoch:  300 0.016472409840697987 1.289021\n",
      "EarlyStopping counter: 86 out of 100\n",
      "epoch:  301 0.01577690959868833 1.2220389\n",
      "EarlyStopping counter: 87 out of 100\n",
      "epoch:  302 0.01970655629679792 1.1707277\n",
      "EarlyStopping counter: 88 out of 100\n",
      "epoch:  303 0.017958231765917293 1.0544634\n",
      "EarlyStopping counter: 89 out of 100\n",
      "epoch:  304 0.017515295088092925 1.23917\n",
      "EarlyStopping counter: 90 out of 100\n",
      "epoch:  305 0.01873297851425317 1.5161643\n",
      "EarlyStopping counter: 91 out of 100\n",
      "epoch:  306 0.01852133083766421 1.1412946\n",
      "EarlyStopping counter: 92 out of 100\n",
      "epoch:  307 0.018775593580269232 1.2060962\n",
      "EarlyStopping counter: 93 out of 100\n",
      "epoch:  308 0.017427403958898427 0.97098196\n",
      "Validation loss decreased (0.984301 --> 0.970982).  Saving model ...\n",
      "epoch:  309 0.017087201742732077 1.3923012\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  310 0.016406806561674616 1.2507033\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  311 0.015962475394528615 1.2554685\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  312 0.01748595956688181 1.5122164\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  313 0.018330391760742058 1.0124439\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  314 0.01830665478090489 1.3517839\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  315 0.018317979060427314 1.2798502\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  316 0.018608156087789724 1.161186\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  317 0.016753094407116493 1.536016\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  318 0.017992048836137663 1.1296312\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  319 0.01852893847517851 1.093875\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  320 0.016296174740645944 1.1552073\n",
      "EarlyStopping counter: 12 out of 100\n",
      "epoch:  321 0.016430784636352648 1.1891718\n",
      "EarlyStopping counter: 13 out of 100\n",
      "epoch:  322 0.015443577296916238 1.2284553\n",
      "EarlyStopping counter: 14 out of 100\n",
      "epoch:  323 0.016299899250368056 1.0111294\n",
      "EarlyStopping counter: 15 out of 100\n",
      "epoch:  324 0.0193168608814544 1.3732862\n",
      "EarlyStopping counter: 16 out of 100\n",
      "epoch:  325 0.015281875661167496 1.1469371\n",
      "EarlyStopping counter: 17 out of 100\n",
      "epoch:  326 0.01642726656635955 1.4129403\n",
      "EarlyStopping counter: 18 out of 100\n",
      "epoch:  327 0.0164718544750811 1.1597738\n",
      "EarlyStopping counter: 19 out of 100\n",
      "epoch:  328 0.016602328175187375 0.9223434\n",
      "Validation loss decreased (0.970982 --> 0.922343).  Saving model ...\n",
      "epoch:  329 0.01680980294843735 1.0053536\n",
      "EarlyStopping counter: 1 out of 100\n",
      "epoch:  330 0.014640539727625985 1.2371535\n",
      "EarlyStopping counter: 2 out of 100\n",
      "epoch:  331 0.015011433045278631 1.0772401\n",
      "EarlyStopping counter: 3 out of 100\n",
      "epoch:  332 0.014819808795783842 1.1702002\n",
      "EarlyStopping counter: 4 out of 100\n",
      "epoch:  333 0.016440671738526244 1.0128088\n",
      "EarlyStopping counter: 5 out of 100\n",
      "epoch:  334 0.01503934746736169 1.4087718\n",
      "EarlyStopping counter: 6 out of 100\n",
      "epoch:  335 0.016714858514837044 0.99792236\n",
      "EarlyStopping counter: 7 out of 100\n",
      "epoch:  336 0.016449976208601187 0.964068\n",
      "EarlyStopping counter: 8 out of 100\n",
      "epoch:  337 0.0170658399452127 1.3346485\n",
      "EarlyStopping counter: 9 out of 100\n",
      "epoch:  338 0.01657988448232875 1.2102811\n",
      "EarlyStopping counter: 10 out of 100\n",
      "epoch:  339 0.016799454620632523 1.1581116\n",
      "EarlyStopping counter: 11 out of 100\n",
      "epoch:  340 0.014136987864277315 1.059764\n",
      "EarlyStopping counter: 12 out of 100\n",
      "epoch:  341 0.01365166106271638 0.98909056\n",
      "EarlyStopping counter: 13 out of 100\n",
      "epoch:  342 0.015426723860584184 1.1054227\n",
      "EarlyStopping counter: 14 out of 100\n",
      "epoch:  343 0.016050827864995287 1.3785956\n",
      "EarlyStopping counter: 15 out of 100\n",
      "epoch:  344 0.01692650847946461 1.1971792\n",
      "EarlyStopping counter: 16 out of 100\n",
      "epoch:  345 0.01552263903379969 1.4283277\n",
      "EarlyStopping counter: 17 out of 100\n",
      "epoch:  346 0.015882940401226085 1.284066\n",
      "EarlyStopping counter: 18 out of 100\n",
      "epoch:  347 0.015343862063274151 1.4092438\n",
      "EarlyStopping counter: 19 out of 100\n",
      "epoch:  348 0.015484327652766276 1.1628014\n",
      "EarlyStopping counter: 20 out of 100\n",
      "epoch:  349 0.014889580100576524 1.0756202\n",
      "EarlyStopping counter: 21 out of 100\n",
      "epoch:  350 0.015016673331018826 1.1662273\n",
      "EarlyStopping counter: 22 out of 100\n",
      "epoch:  351 0.016012369124363372 1.1059633\n",
      "EarlyStopping counter: 23 out of 100\n",
      "epoch:  352 0.013726027034008319 1.3327788\n",
      "EarlyStopping counter: 24 out of 100\n",
      "epoch:  353 0.01689771057298601 1.0111283\n",
      "EarlyStopping counter: 25 out of 100\n",
      "epoch:  354 0.013463806245319065 1.3442507\n",
      "EarlyStopping counter: 26 out of 100\n",
      "epoch:  355 0.015412904264326899 1.1100547\n",
      "EarlyStopping counter: 27 out of 100\n",
      "epoch:  356 0.01564519668200328 0.98566735\n",
      "EarlyStopping counter: 28 out of 100\n",
      "epoch:  357 0.013994120746983129 1.5879642\n",
      "EarlyStopping counter: 29 out of 100\n",
      "epoch:  358 0.0171544746456548 1.115148\n",
      "EarlyStopping counter: 30 out of 100\n",
      "epoch:  359 0.015503402055961858 1.2576948\n",
      "EarlyStopping counter: 31 out of 100\n",
      "epoch:  360 0.01326809943284005 1.1645277\n",
      "EarlyStopping counter: 32 out of 100\n",
      "epoch:  361 0.015780890348084487 1.4205956\n",
      "EarlyStopping counter: 33 out of 100\n",
      "epoch:  362 0.016781901763111947 1.2077789\n",
      "EarlyStopping counter: 34 out of 100\n",
      "epoch:  363 0.013196455657548227 1.2448759\n",
      "EarlyStopping counter: 35 out of 100\n",
      "epoch:  364 0.013313795280892675 1.2540585\n",
      "EarlyStopping counter: 36 out of 100\n",
      "epoch:  365 0.014094029559429627 0.98662335\n",
      "EarlyStopping counter: 37 out of 100\n",
      "epoch:  366 0.013297245534190582 1.2574968\n",
      "EarlyStopping counter: 38 out of 100\n",
      "epoch:  367 0.017300140641282772 1.116726\n",
      "EarlyStopping counter: 39 out of 100\n",
      "epoch:  368 0.017101254652846943 1.2028253\n",
      "EarlyStopping counter: 40 out of 100\n",
      "epoch:  369 0.015135796926502642 1.115763\n",
      "EarlyStopping counter: 41 out of 100\n",
      "epoch:  370 0.0160132808127583 1.0317214\n",
      "EarlyStopping counter: 42 out of 100\n",
      "epoch:  371 0.016231696334091363 1.0296519\n",
      "EarlyStopping counter: 43 out of 100\n",
      "epoch:  372 0.01389293836020842 1.2228088\n",
      "EarlyStopping counter: 44 out of 100\n",
      "epoch:  373 0.015763212499227335 1.1608105\n",
      "EarlyStopping counter: 45 out of 100\n",
      "epoch:  374 0.014372440575396935 1.0209601\n",
      "EarlyStopping counter: 46 out of 100\n",
      "epoch:  375 0.014344126068699914 1.3007127\n",
      "EarlyStopping counter: 47 out of 100\n",
      "epoch:  376 0.016695290039853088 1.4339311\n",
      "EarlyStopping counter: 48 out of 100\n",
      "epoch:  377 0.016049262437713385 0.970216\n",
      "EarlyStopping counter: 49 out of 100\n",
      "epoch:  378 0.014603080042119566 0.9519792\n",
      "EarlyStopping counter: 50 out of 100\n",
      "epoch:  379 0.014162067315663043 1.2103187\n",
      "EarlyStopping counter: 51 out of 100\n",
      "epoch:  380 0.013100893887177011 1.070863\n",
      "EarlyStopping counter: 52 out of 100\n",
      "epoch:  381 0.013845917589119955 1.1117182\n",
      "EarlyStopping counter: 53 out of 100\n",
      "epoch:  382 0.015933982631451803 1.1741381\n",
      "EarlyStopping counter: 54 out of 100\n",
      "epoch:  383 0.014110473271649323 1.1568666\n",
      "EarlyStopping counter: 55 out of 100\n",
      "epoch:  384 0.013898881800687497 1.2448323\n",
      "EarlyStopping counter: 56 out of 100\n",
      "epoch:  385 0.013395392887310812 1.1859188\n",
      "EarlyStopping counter: 57 out of 100\n",
      "epoch:  386 0.014269713060455417 1.4741892\n",
      "EarlyStopping counter: 58 out of 100\n",
      "epoch:  387 0.013693951062048617 1.2238903\n",
      "EarlyStopping counter: 59 out of 100\n",
      "epoch:  388 0.014396917587042913 1.1228439\n",
      "EarlyStopping counter: 60 out of 100\n",
      "epoch:  389 0.015580982473697472 1.4582313\n",
      "EarlyStopping counter: 61 out of 100\n",
      "epoch:  390 0.013085601640712395 1.120175\n",
      "EarlyStopping counter: 62 out of 100\n",
      "epoch:  391 0.014912579662916137 1.0318663\n",
      "EarlyStopping counter: 63 out of 100\n",
      "epoch:  392 0.013043186245300289 1.2766337\n",
      "EarlyStopping counter: 64 out of 100\n",
      "epoch:  393 0.01565453054965732 1.2030487\n",
      "EarlyStopping counter: 65 out of 100\n",
      "epoch:  394 0.014957430753898198 0.98878264\n",
      "EarlyStopping counter: 66 out of 100\n",
      "epoch:  395 0.015342512066804384 1.4440817\n",
      "EarlyStopping counter: 67 out of 100\n",
      "epoch:  396 0.012876232846448003 1.49128\n",
      "EarlyStopping counter: 68 out of 100\n",
      "epoch:  397 0.014100373955959755 1.3025458\n",
      "EarlyStopping counter: 69 out of 100\n",
      "epoch:  398 0.014019199582993852 1.3354615\n",
      "EarlyStopping counter: 70 out of 100\n",
      "epoch:  399 0.01309103729769158 1.1462837\n",
      "EarlyStopping counter: 71 out of 100\n",
      "epoch:  400 0.013334306506254192 1.1861194\n",
      "EarlyStopping counter: 72 out of 100\n",
      "epoch:  401 0.012872537292391392 1.1488119\n",
      "EarlyStopping counter: 73 out of 100\n",
      "epoch:  402 0.014284123891671323 1.2957796\n",
      "EarlyStopping counter: 74 out of 100\n",
      "epoch:  403 0.013674786037655998 1.2236131\n",
      "EarlyStopping counter: 75 out of 100\n",
      "epoch:  404 0.013366579245404235 1.0627177\n",
      "EarlyStopping counter: 76 out of 100\n",
      "epoch:  405 0.013793290115711166 1.1478381\n",
      "EarlyStopping counter: 77 out of 100\n",
      "epoch:  406 0.012641742982449394 0.9727783\n",
      "EarlyStopping counter: 78 out of 100\n",
      "epoch:  407 0.014159259875769626 1.095699\n",
      "EarlyStopping counter: 79 out of 100\n",
      "epoch:  408 0.013636498800798954 1.3399436\n",
      "EarlyStopping counter: 80 out of 100\n",
      "epoch:  409 0.013362570242448286 1.3085313\n",
      "EarlyStopping counter: 81 out of 100\n",
      "epoch:  410 0.01460314023322911 1.261862\n",
      "EarlyStopping counter: 82 out of 100\n",
      "epoch:  411 0.014307511623477988 1.4599633\n",
      "EarlyStopping counter: 83 out of 100\n",
      "epoch:  412 0.01420066316515009 1.0732908\n",
      "EarlyStopping counter: 84 out of 100\n",
      "epoch:  413 0.016099876193474243 1.1649431\n",
      "EarlyStopping counter: 85 out of 100\n",
      "epoch:  414 0.012828900352814246 1.2793127\n",
      "EarlyStopping counter: 86 out of 100\n",
      "epoch:  415 0.014195410291067512 1.2935536\n",
      "EarlyStopping counter: 87 out of 100\n",
      "epoch:  416 0.011966645300487458 1.154443\n",
      "EarlyStopping counter: 88 out of 100\n",
      "epoch:  417 0.013319311940220666 1.3651454\n",
      "EarlyStopping counter: 89 out of 100\n",
      "epoch:  418 0.012436516297993533 1.2191048\n",
      "EarlyStopping counter: 90 out of 100\n",
      "epoch:  419 0.013575468063684894 1.2820199\n",
      "EarlyStopping counter: 91 out of 100\n",
      "epoch:  420 0.013062092077044849 1.3200171\n",
      "EarlyStopping counter: 92 out of 100\n",
      "epoch:  421 0.013461990236509137 1.2090443\n",
      "EarlyStopping counter: 93 out of 100\n",
      "epoch:  422 0.011805739328099989 1.125919\n",
      "EarlyStopping counter: 94 out of 100\n",
      "epoch:  423 0.014357136236193968 1.5387849\n",
      "EarlyStopping counter: 95 out of 100\n",
      "epoch:  424 0.014844332237267442 1.1991223\n",
      "EarlyStopping counter: 96 out of 100\n",
      "epoch:  425 0.014147875950302095 1.0919114\n",
      "EarlyStopping counter: 97 out of 100\n",
      "epoch:  426 0.011743907798122937 1.0687822\n",
      "EarlyStopping counter: 98 out of 100\n",
      "epoch:  427 0.013586855336544652 1.1544384\n",
      "EarlyStopping counter: 99 out of 100\n",
      "epoch:  428 0.01383234615006098 1.5690004\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Early stopping\n",
      "/Users/htdvu/Desktop/myLab/myLab-HDAC6-results/notebooks/FragNet/fragnet/train/finetune/finetune_gat2.py:286: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ft_chk_point))\n",
      "val_res rmse:  0.9603870955498335\n",
      "test_res rmse:  0.8985053990456069\n"
     ]
    }
   ],
   "source": [
    "!python train/finetune/finetune_gat2.py --config exps/ft/esol/e1pt4.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e983b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylab-hdac6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
